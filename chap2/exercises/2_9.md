> Consider the following CUDA kernel and the corresponding host function that calls it:

```c++
01  __global__ void foo_kernel(float* a, float* b, unsigned int N) {
02      unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
x:
03      if (i < N) {
04          b[i] = 2.7f * a[i] - 4.3f;
05      }
06  }
07  void foo(float* a_d, float* b_d) {
08      unsigned int N = 200000;
09      foo_kernel <<<(N + 128 - 1) / 128, 128>>>(a_d, b_d, N);
10  }
```

> a. What is the number of threads per block?

128

> b. What is the number of blocks in the grid?

200064

> c. What is the number of blocks in the grid?

1563

> d. What is the number of threads that execute the code on line 02?

200064

> e. What is the number of threads that execute the code on line 04?

200000
